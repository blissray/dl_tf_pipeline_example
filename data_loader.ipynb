{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-12T07:46:14.360671Z",
     "start_time": "2017-08-12T07:46:13.322694Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-12T07:46:14.365129Z",
     "start_time": "2017-08-12T07:46:14.361934Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IMAGE_DIR = \"Images\"\n",
    "ANNOTATION_DIR = \"Annotation\"\n",
    "\n",
    "bleeds = os.listdir(ANNOTATION_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-12T07:46:14.369253Z",
     "start_time": "2017-08-12T07:46:14.366685Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_set = {}\n",
    "annotation_set = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-12T07:46:14.397627Z",
     "start_time": "2017-08-12T07:46:14.370834Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for bleed in bleeds:\n",
    "    image_dir = os.path.join(IMAGE_DIR, bleed)\n",
    "    annotation_dir = os.path.join(ANNOTATION_DIR, bleed)\n",
    "    image_set[bleed] = os.listdir(image_dir)\n",
    "    annotation_set[bleed] = os.listdir(annotation_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-12T07:46:14.417926Z",
     "start_time": "2017-08-12T07:46:14.399106Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_data = []\n",
    "for bleed in image_set.keys():\n",
    "    total_data.extend([ [filename,bleed] for filename in image_set[bleed]])\n",
    "total_data = np.array(total_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-12T07:46:14.689225Z",
     "start_time": "2017-08-12T07:46:14.419198Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     total_data[:,0], total_data[:,1], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-12T07:46:14.695810Z",
     "start_time": "2017-08-12T07:46:14.690913Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "\n",
    "x_data = X_train\n",
    "y_data = y_train\n",
    "current_index = 0\n",
    "\n",
    "\n",
    "record_location = \"./output/images\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-12T07:46:25.219656Z",
     "start_time": "2017-08-12T07:46:14.701341Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "writer = None\n",
    "current_index = 0\n",
    "\n",
    "\n",
    "for images_filename,breed in zip(x_data,y_data):\n",
    "\n",
    "    if current_index % 100 == 0:\n",
    "        \n",
    "        if writer:\n",
    "            writer.close()\n",
    "        record_filename = \"{record_location}-{current_index}.tfrecords\".format(\n",
    "            record_location=record_location, current_index=current_index\n",
    "        )\n",
    "\n",
    "        writer = tf.python_io.TFRecordWriter(record_filename)\n",
    "        file_full_path = os.path.join(IMAGE_DIR, breed,  images_filename)\n",
    "                \n",
    "        image_file = tf.read_file(file_full_path)\n",
    "        try:\n",
    "            image = tf.image.decode_jpeg(image_file)\n",
    "        except:\n",
    "            print(\"Error : \", images_filename)\n",
    "            continue\n",
    "\n",
    "\n",
    "        grayscale_image = tf.image.rgb_to_grayscale(image)\n",
    "        resized_image = tf.image.resize_images(grayscale_image, [250, 151])\n",
    "        \n",
    "        image_bytes = sess.run(tf.cast(resized_image, tf.uint8)).tobytes()\n",
    "        image_label = breed.encode(\"utf-8\")\n",
    "        \n",
    "        example = tf.train.Example(features = tf.train.Features(\n",
    "                                    feature={'label': \n",
    "                                              tf.train.Feature(bytes_list=tf.train.BytesList(\n",
    "                                                  value=[image_label])), \n",
    "                                              \"images\":\n",
    "                                              tf.train.Feature(bytes_list=tf.train.BytesList(\n",
    "                                                  value=[image_bytes]))\n",
    "                                             }\n",
    "                                  ))\n",
    "        writer.write(example.SerializeToString())\n",
    "    current_index += 1\n",
    "    writer.close()\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-12T07:46:55.273564Z",
     "start_time": "2017-08-12T07:46:55.148402Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "filenmae_queue = tf.train.string_input_producer(tf.train.match_filenames_once(record_location+\"*.tfrecords\"))\n",
    "\n",
    "reader = tf.TFRecordReader()\n",
    "_, serialized = reader.read(filenmae_queue)\n",
    "\n",
    "features = tf.parse_single_example(\n",
    "    serialized,\n",
    "    features={\n",
    "        \"label\" : tf.FixedLenFeature([], tf.string),\n",
    "        \"image\" : tf.FixedLenFeature([], tf.string),\n",
    "    }\n",
    ")\n",
    "\n",
    "record_image = tf.decode_raw(features['image'], tf.uint8)\n",
    "image = tf.reshape(record_image, [250,151,1])\n",
    "label = tf.cast(features['label'], tf.string)\n",
    "\n",
    "min_after_dequeue = 10\n",
    "batch_size = 512\n",
    "capacity = min_after_dequeue + 3 * batch_size\n",
    "\n",
    "image_batch, label_batch = tf.train.shuffle_batch([image, label], batch_size=batch_size, capacity=capacity, min_after_dequeue=min_after_dequeue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-12T08:33:31.432308Z",
     "start_time": "2017-08-12T08:33:31.394052Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'MaxPool_9:0' shape=(512, 125, 76, 32) dtype=float32>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_image_batch = tf.image.convert_image_dtype(image_batch, tf.float32)\n",
    "\n",
    "conv2d_layer_one = tf.contrib.layers.convolution2d(float_image_batch, \n",
    "                                                   num_outputs=32,\n",
    "                                                   activation_fn=tf.nn.relu,\n",
    "                                                   kernel_size=(5,5),\n",
    "                                                   stride=(1,1),\n",
    "                                                   trainable=True)\n",
    "pool_layer_one = tf.nn.max_pool(conv2d_layer_one, ksize=[1,2,2,1], strides=[1,2,2,1], padding=\"SAME\")\n",
    "\n",
    "pool_layer_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-12T08:36:01.275532Z",
     "start_time": "2017-08-12T08:36:01.246857Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor 'Conv_18/Relu:0' shape=(512, 125, 76, 64) dtype=float32>,\n",
       " <tf.Tensor 'MaxPool_13:0' shape=(512, 63, 38, 64) dtype=float32>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d_layer_two = tf.contrib.layers.convolution2d(pool_layer_one, \n",
    "                                                   num_outputs=64,\n",
    "                                                   activation_fn=tf.nn.relu,\n",
    "                                                   kernel_size=(5,5),\n",
    "                                                   stride=(1,1),\n",
    "                                                   trainable=True)\n",
    "\n",
    "pool_layer_two = tf.nn.max_pool(conv2d_layer_two, ksize=[1,2,2,1], strides=[1,2,2,1], padding=\"SAME\")\n",
    "\n",
    "conv2d_layer_two, pool_layer_two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-12T08:39:24.182435Z",
     "start_time": "2017-08-12T08:39:24.174086Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.framework.tensor_shape.Dimension"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flattened_layer_two = tf.reshape(\n",
    "    pool_layer_two,\n",
    "    [\n",
    "        batch_size, -1\n",
    "    ]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-12T08:40:13.424090Z",
     "start_time": "2017-08-12T08:40:13.402710Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "hidden_layer_three = tf.contrib.layers.fully_connected(\n",
    "    flattened_layer_two, num_outputs = batch_size\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
